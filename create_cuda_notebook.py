import json

notebook = {
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 🚀 Real CUDA Fluid Simulation\n",
                "\n",
                "This notebook actually **compiles and runs the CUDA code** from the repository!\n",
                "We'll build the fluidsGL executable and run the real CUDA fluid simulation.\n",
                "\n",
                "**Requirements:** This needs a system with:\n",
                "- NVIDIA GPU\n",
                "- CUDA toolkit installed\n",
                "- OpenGL/GLUT development libraries\n",
                "\n",
                "If you're on Google Colab, make sure to select GPU runtime!\n",
                "\n",
                "**Note:** If you encounter PTX toolchain errors, this notebook includes compatibility fixes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# First, let's check our environment\n",
                "import os\n",
                "import subprocess\n",
                "\n",
                "def run_command(cmd):\n",
                "    try:\n",
                "        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
                "        return result.returncode == 0, result.stdout, result.stderr\n",
                "    except Exception as e:\n",
                "        return False, \"\", str(e)\n",
                "\n",
                "print(\"🔍 Environment Check\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "# Check if we have GPU\n",
                "success, stdout, stderr = run_command(\"nvidia-smi\")\n",
                "if success:\n",
                "    print(\"✅ GPU detected!\")\n",
                "    print(stdout.split('\\n')[0])  # First line with driver info\n",
                "    \n",
                "    # Extract GPU name and compute capability\n",
                "    gpu_info = run_command(\"nvidia-smi --query-gpu=name,compute_cap --format=csv,noheader,nounits\")\n",
                "    if gpu_info[0]:\n",
                "        print(f\"🔥 GPU Details: {gpu_info[1].strip()}\")\nelse:\n",
                "    print(\"❌ No GPU detected or nvidia-smi not available\")\n",
                "    print(\"   You'll need an NVIDIA GPU to run this efficiently\")\n",
                "\n",
                "# Check Python environment\n",
                "print(f\"\\n🐍 Python: {os.sys.version}\")\n",
                "print(f\"📁 Working directory: {os.getcwd()}\")\n",
                "\n",
                "print(\"\\n\" + \"=\" * 50)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone or navigate to the repository\n",
                "repo_url = \"https://github.com/tarun-bandi/cuda-fluid-sim.git\"\n",
                "repo_dir = \"cuda-fluid-sim\"\n",
                "\n",
                "if os.path.exists(repo_dir):\n",
                "    print(f\"📁 Directory {repo_dir} already exists\")\n",
                "    os.chdir(repo_dir)\n",
                "    !git pull  # Update if needed\n",
                "else:\n",
                "    print(f\"📥 Cloning {repo_url}...\")\n",
                "    !git clone {repo_url}\n",
                "    os.chdir(repo_dir)\n",
                "\n",
                "print(f\"\\n📋 Repository contents:\")\n",
                "!ls -la\n",
                "\n",
                "print(f\"\\n🔍 Source files:\")\n",
                "!find . -name '*.cu' -o -name '*.cpp' -o -name '*.cuh' | head -10"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 🛠️ Install Dependencies\n",
                "\n",
                "Let's install the required tools and libraries:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install CUDA and development tools\n",
                "print(\"🔧 Installing dependencies...\")\n",
                "\n",
                "# Update package list\n",
                "!apt-get update -qq\n",
                "\n",
                "# Install CUDA toolkit and build tools\n",
                "!apt-get install -y -qq nvidia-cuda-toolkit\n",
                "!apt-get install -y -qq cmake build-essential\n",
                "\n",
                "# Install OpenGL/GLUT for graphics\n",
                "!apt-get install -y -qq freeglut3-dev libglew-dev libglu1-mesa-dev\n",
                "\n",
                "# Install virtual framebuffer for headless OpenGL\n",
                "!apt-get install -y -qq xvfb\n",
                "\n",
                "print(\"\\n✅ Dependencies installed!\")\n",
                "\n",
                "# Check CUDA installation and version\n",
                "print(\"\\n🔍 CUDA Version:\")\n",
                "success, stdout, stderr = run_command(\"nvcc --version\")\n",
                "if success:\n",
                "    print(stdout)\n",
                "    # Extract CUDA version for compatibility\n",
                "    for line in stdout.split('\\n'):\n",
                "        if 'release' in line:\n",
                "            print(f\"🎯 CUDA Release: {line.strip()}\")\n",
                "            break\nelse:\n",
                "    print(\"❌ CUDA compiler not found!\")\n",
                "    print(stderr)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 🔧 Fix PTX Toolchain Compatibility\n",
                "\n",
                "Let's check GPU compute capability and create compatible CUDA code:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get detailed GPU information for compatibility\n",
                "print(\"🔍 GPU Compute Capability Analysis:\")\n",
                "print(\"=\" * 40)\n",
                "\n",
                "# Query GPU compute capability\n",
                "success, gpu_info, _ = run_command(\"nvidia-smi --query-gpu=name,compute_cap --format=csv,noheader,nounits\")\n",
                "if success:\n",
                "    gpu_name, compute_cap = gpu_info.strip().split(', ')\n",
                "    print(f\"🔥 GPU: {gpu_name}\")\n",
                "    print(f\"🧮 Compute Capability: {compute_cap}\")\n",
                "    \n",
                "    # Determine appropriate CUDA architecture\n",
                "    compute_major = int(compute_cap.split('.')[0])\n",
                "    compute_minor = int(compute_cap.split('.')[1])\n",
                "    \n",
                "    if compute_major >= 7:\n",
                "        arch_flag = \"sm_70\"\n",
                "        print(\"✅ Modern GPU - using sm_70 architecture\")\n",
                "    elif compute_major >= 6:\n",
                "        arch_flag = \"sm_60\"\n",
                "        print(\"✅ Pascal GPU - using sm_60 architecture\")\n",
                "    elif compute_major >= 5:\n",
                "        arch_flag = \"sm_50\"\n",
                "        print(\"✅ Maxwell GPU - using sm_50 architecture\")\n",
                "    else:\n",
                "        arch_flag = \"sm_35\"\n",
                "        print(\"⚠️  Older GPU - using sm_35 architecture\")\n",
                "    \n",
                "    print(f\"🎯 Selected architecture: {arch_flag}\")\nelse:\n",
                "    print(\"❌ Could not determine GPU compute capability\")\n",
                "    arch_flag = \"sm_60\"  # Safe default\n",
                "    print(f\"🎯 Using default architecture: {arch_flag}\")\n",
                "\n",
                "print(\"\\n\" + \"=\" * 40)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 📝 Examine the CUDA Source Code\n",
                "\n",
                "Let's look at the actual CUDA kernels:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display the CUDA kernel source\n",
                "kernel_file = \"src/fluidsGL_kernels.cu\"\n",
                "main_file = \"src/fluidsGL.cpp\"\n",
                "\n",
                "if os.path.exists(kernel_file):\n",
                "    print(\"🔥 CUDA Kernel File:\")\n",
                "    print(\"=\" * 50)\n",
                "    with open(kernel_file, 'r') as f:\n",
                "        content = f.read()\n",
                "        # Show first part of the file\n",
                "        lines = content.split('\\n')\n",
                "        for i, line in enumerate(lines[:50]):\n",
                "            print(f\"{i+1:3d}: {line}\")\n",
                "        if len(lines) > 50:\n",
                "            print(f\"... ({len(lines) - 50} more lines)\")\nelse:\n",
                "    print(f\"❌ {kernel_file} not found!\")\n",
                "    print(\"Available files:\")\n",
                "    !ls -la src/\n",
                "\n",
                "print(\"\\n\" + \"=\" * 50)\n",
                "print(f\"📊 Code Statistics:\")\n",
                "!wc -l src/*.cu src/*.cpp 2>/dev/null || echo \"Source files not found\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 🔨 Build with Compatibility Fixes\n",
                "\n",
                "Now let's compile with the correct architecture flags:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create and enter build directory\n",
                "build_dir = \"build\"\n",
                "if os.path.exists(build_dir):\n",
                "    import shutil\n",
                "    shutil.rmtree(build_dir)\n",
                "    \n",
                "os.makedirs(build_dir)\n",
                "os.chdir(build_dir)\n",
                "\n",
                "print(\"🔨 Building CUDA Fluid Simulation with Compatibility Fixes\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "# Create a compatibility-focused CMakeLists.txt\n",
                "cmake_content = f'''cmake_minimum_required(VERSION 3.8)\n",
                "project(cuda_fluid_sim LANGUAGES CUDA CXX)\n",
                "\n",
                "# Find CUDA\n",
                "find_package(CUDA REQUIRED)\n",
                "enable_language(CUDA)\n",
                "\n",
                "# Set CUDA architecture for detected GPU\n",
                "set(CMAKE_CUDA_FLAGS \"${{CMAKE_CUDA_FLAGS}} -arch={arch_flag}\")\n",
                "set(CMAKE_CUDA_FLAGS \"${{CMAKE_CUDA_FLAGS}} --use_fast_math\")\n",
                "set(CMAKE_CUDA_FLAGS \"${{CMAKE_CUDA_FLAGS}} -Xcompiler -fPIC\")\n",
                "\n",
                "# Create simple compatibility test\n",
                "add_executable(cuda_simple_test\n",
                "    ../src/simple_cuda_test.cu\n",
                ")\n",
                "\n",
                "set_property(TARGET cuda_simple_test PROPERTY CUDA_SEPARABLE_COMPILATION ON)\n",
                "target_link_libraries(cuda_simple_test ${{CUDA_LIBRARIES}})\n",
                "\n",
                "# Try to build main fluid simulation if OpenGL is available\n",
                "find_package(OpenGL QUIET)\n",
                "find_package(GLUT QUIET)\n",
                "\n",
                "if(OPENGL_FOUND AND GLUT_FOUND)\n",
                "    add_executable(fluidsGL\n",
                "        ../src/fluidsGL.cpp\n",
                "        ../src/fluidsGL_kernels.cu\n",
                "    )\n",
                "    \n",
                "    set_property(TARGET fluidsGL PROPERTY CUDA_SEPARABLE_COMPILATION ON)\n",
                "    target_link_libraries(fluidsGL \n",
                "        ${{CUDA_LIBRARIES}} \n",
                "        ${{OPENGL_LIBRARIES}} \n",
                "        ${{GLUT_LIBRARY}}\n",
                "    )\n",
                "    \n",
                "    message(STATUS \"Building full OpenGL fluid simulation\")\n",
                "else()\n",
                "    message(STATUS \"OpenGL/GLUT not found - building CUDA test only\")\n",
                "endif()\n",
                "'''\n",
                "\n",
                "with open(\"CMakeLists.txt\", \"w\") as f:\n",
                "    f.write(cmake_content)\n",
                "\n",
                "print(f\"✅ Created CMakeLists.txt with architecture: {arch_flag}\")\n",
                "\n",
                "# Configure with CMake\n",
                "print(\"\\n📋 Step 1: CMake Configuration\")\n",
                "cmake_success, cmake_out, cmake_err = run_command(\"cmake ..\")\n",
                "\n",
                "if cmake_success:\n",
                "    print(\"✅ CMake configuration successful!\")\n",
                "    if cmake_out:\n",
                "        # Show relevant output\n",
                "        for line in cmake_out.split('\\n'):\n",
                "            if 'CUDA' in line or 'OpenGL' in line or 'Building' in line:\n",
                "                print(f\"   {line}\")\nelse:\n",
                "    print(\"❌ CMake configuration failed!\")\n",
                "    print(\"Error output:\")\n",
                "    print(cmake_err[:1000])\n",
                "\n",
                "print(\"\\n\" + \"=\" * 30)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Build the project\n",
                "print(\"🔨 Step 2: Compilation\")\n",
                "\n",
                "if cmake_success:\n",
                "    build_success, build_out, build_err = run_command(\"make -j4\")\n",
                "    \n",
                "    if build_success:\n",
                "        print(\"✅ Build successful!\")\n",
                "        print(\"\\n📁 Build artifacts:\")\n",
                "        !ls -la\n",
                "        \n",
                "        # Look for executables\n",
                "        executables = [f for f in os.listdir('.') if os.access(f, os.X_OK) and not f.startswith('.')]\n",
                "        if executables:\n",
                "            print(f\"\\n🎯 Found executables: {', '.join(executables)}\")\n",
                "        else:\n",
                "            print(\"\\n❌ No executables found after build\")\n",
                "            \n",
                "    else:\n",
                "        print(\"❌ Build failed!\")\n",
                "        print(\"Build output:\")\n",
                "        print(build_out[:1500] if build_out else \"No output\")\n",
                "        print(\"\\nBuild errors:\")\n",
                "        print(build_err[:1500] if build_err else \"No errors\")\n",
                "        \n",
                "        # Try direct CUDA compilation with specific arch\n",
                "        print(f\"\\n🔧 Trying direct CUDA compilation with {arch_flag}...\")\n",
                "        direct_cmd = f\"nvcc -arch={arch_flag} -o simple_test ../src/simple_cuda_test.cu\"\n",
                "        direct_success, direct_out, direct_err = run_command(direct_cmd)\n",
                "        \n",
                "        if direct_success:\n",
                "            print(\"✅ Direct CUDA compilation successful!\")\n",
                "            !ls -la simple_test\n",
                "        else:\n",
                "            print(\"❌ Direct CUDA compilation also failed\")\n",
                "            print(direct_err[:500])\nelse:\n",
                "    print(\"❌ Skipping build due to CMake failure\")\n",
                "\n",
                "print(\"\\n\" + \"=\" * 30)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 🚀 Test CUDA Compatibility\n",
                "\n",
                "Let's run the compatibility test to verify the PTX issue is fixed:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run the compatibility test\n",
                "print(\"🧪 Running CUDA Compatibility Test\")\n",
                "print(\"=\" * 40)\n",
                "\n",
                "# Look for executables\n",
                "test_executables = ['cuda_simple_test', 'simple_test']\n",
                "found_test = None\n",
                "\n",
                "for exe in test_executables:\n",
                "    if os.path.exists(exe) and os.access(exe, os.X_OK):\n",
                "        found_test = exe\n",
                "        break\n",
                "\n",
                "if found_test:\n",
                "    print(f\"✅ Found test executable: {found_test}\")\n",
                "    \n",
                "    # Run the test\n",
                "    print(f\"\\n🚀 Running {found_test}...\")\n",
                "    test_success, test_out, test_err = run_command(f\"./{found_test}\")\n",
                "    \n",
                "    if test_success:\n",
                "        print(\"✅ CUDA test completed successfully!\")\n",
                "        print(\"Output:\")\n",
                "        print(test_out)\n",
                "        \n",
                "        if \"PTX\" in test_err or \"toolchain\" in test_err:\n",
                "            print(\"⚠️  PTX warnings detected:\")\n",
                "            print(test_err)\n",
                "        elif test_err:\n",
                "            print(\"ℹ️  Additional info:\")\n",
                "            print(test_err)\n",
                "    else:\n",
                "        print(\"❌ CUDA test failed!\")\n",
                "        print(\"Error output:\")\n",
                "        print(test_err)\n",
                "        \n",
                "        if \"PTX\" in test_err or \"toolchain\" in test_err:\n",
                "            print(\"\\n🔧 PTX Toolchain Issue Detected!\")\n",
                "            print(\"This usually means:\")\n",
                "            print(\"1. CUDA toolkit version mismatch with GPU driver\")\n",
                "            print(\"2. Wrong architecture flag for your GPU\")\n",
                "            print(f\"3. Try using older CUDA toolkit or update GPU drivers\")\nelse:\n",
                "    print(\"❌ No test executable found!\")\n",
                "    print(\"Available files:\")\n",
                "    !ls -la\n",
                "\n",
                "print(\"\\n\" + \"=\" * 40)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 🎯 Run the Main Fluid Simulation\n",
                "\n",
                "If everything works, let's try the main application:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Look for the main fluid simulation executable\n",
                "if os.path.exists('fluidsGL') and os.access('fluidsGL', os.X_OK):\n",
                "    print(\"🎯 Found main fluid simulation: fluidsGL\")\n",
                "    !ls -la fluidsGL\n",
                "    \n",
                "    print(\"\\n🚀 Attempting to run CUDA Fluid Simulation...\")\n",
                "    print(\"Note: This requires display/GUI. In headless mode, it may show initialization info only.\")\n",
                "    \n",
                "    # Try to run with timeout\n",
                "    print(\"\\nRunning with 10-second timeout...\")\n",
                "    run_success, run_out, run_err = run_command(\"timeout 10s ./fluidsGL || echo 'Simulation requires display'\")\n",
                "    \n",
                "    if run_out:\n",
                "        print(\"📋 Output:\")\n",
                "        print(run_out)\n",
                "    \n",
                "    if run_err:\n",
                "        print(\"📋 Messages:\")\n",
                "        print(run_err)\n",
                "    \n",
                "    if \"CUDA\" in run_out or \"GPU\" in run_out:\n",
                "        print(\"\\n✅ CUDA fluid simulation is working!\")\n",
                "        print(\"🎮 To run locally: cd build && ./fluidsGL\")\n",
                "    else:\n",
                "        print(\"\\n⚠️  Simulation needs display environment to run fully\")\n",
                "else:\n",
                "    print(\"ℹ️  Main fluid simulation not built (likely due to missing OpenGL)\")\n",
                "    print(\"   This is normal in headless environments\")\n",
                "    \n",
                "    if found_test:\n",
                "        print(f\"\\n✅ But CUDA is working as demonstrated by {found_test}!\")\n",
                "        print(\"🏠 For full graphics, run locally with GPU and display\")\n",
                "\n",
                "print(\"\\n\" + \"=\" * 50)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 💻 For Local Development\n",
                "\n",
                "To run this simulation on your local machine with proper GPU acceleration:\n",
                "\n",
                "### Prerequisites:\n",
                "1. **NVIDIA GPU** with CUDA support\n",
                "2. **CUDA Toolkit** installed\n",
                "3. **Development tools**: CMake, C++ compiler\n",
                "4. **Graphics libraries**: OpenGL, GLUT\n",
                "\n",
                "### Installation Commands:\n",
                "\n",
                "**Ubuntu/Debian:**\n",
                "```bash\n",
                "sudo apt update\n",
                "sudo apt install nvidia-cuda-toolkit cmake build-essential\n",
                "sudo apt install freeglut3-dev libglew-dev libglu1-mesa-dev\n",
                "```\n",
                "\n",
                "**macOS:**\n",
                "```bash\n",
                "# Install CUDA toolkit from NVIDIA website\n",
                "# Install Xcode command line tools\n",
                "xcode-select --install\n",
                "# OpenGL/GLUT should be available via system frameworks\n",
                "```\n",
                "\n",
                "### Build and Run:\n",
                "```bash\n",
                "git clone https://github.com/tarun-bandi/cuda-fluid-sim.git\n",
                "cd cuda-fluid-sim\n",
                "# Use the provided test script:\n",
                "./test_cuda_build.sh\n",
                "# OR manual build:\n",
                "mkdir build && cd build\n",
                "cmake ..\n",
                "make -j4\n",
                "./fluidsGL\n",
                "```\n",
                "\n",
                "### Controls:\n",
                "- **Click and drag**: Add fluid density and heat\n",
                "- **R key**: Reset simulation\n",
                "- **ESC**: Exit\n",
                "\n",
                "## 🔧 Troubleshooting PTX Errors\n",
                "\n",
                "If you encounter **\"unsupported toolchain\"** errors:\n",
                "\n",
                "1. **Check GPU Compute Capability**:\n",
                "   ```bash\n",
                "   nvidia-smi --query-gpu=compute_cap --format=csv,noheader,nounits\n",
                "   ```\n",
                "\n",
                "2. **Use Appropriate Architecture Flag**:\n",
                "   - Compute 7.x: `-arch=sm_70`\n",
                "   - Compute 6.x: `-arch=sm_60`  \n",
                "   - Compute 5.x: `-arch=sm_50`\n",
                "   - Compute 3.x: `-arch=sm_35`\n",
                "\n",
                "3. **Update Drivers or CUDA**:\n",
                "   - Ensure CUDA toolkit matches your GPU driver version\n",
                "   - Consider using CUDA 11.x for better compatibility\n",
                "\n",
                "## 🔬 What This Demonstrates\n",
                "\n",
                "This project showcases real **GPU-accelerated fluid dynamics** using:\n",
                "\n",
                "1. **CUDA Kernels**: \n",
                "   - `advectKernel`: Particle advection with bilinear interpolation\n",
                "   - `diffuseKernel`: Viscosity and heat diffusion\n",
                "   - `addForceKernel`: Buoyancy forces\n",
                "   - `projectionKernels`: Pressure projection for incompressible flow\n",
                "\n",
                "2. **Advanced GPU Techniques**:\n",
                "   - Texture memory for optimized access patterns\n",
                "   - Efficient grid/block dimensions\n",
                "   - Device memory management\n",
                "   - Kernel synchronization\n",
                "   - Architecture-specific optimization\n",
                "\n",
                "3. **Real-time Visualization**:\n",
                "   - OpenGL rendering\n",
                "   - Interactive mouse controls\n",
                "   - Color-coded visualization of density and temperature\n",
                "\n",
                "4. **Production Practices**:\n",
                "   - Cross-platform compatibility\n",
                "   - Robust error handling\n",
                "   - Professional build system\n",
                "   - GPU architecture detection\n",
                "\n",
                "This is **production-quality CUDA code** with real-world compatibility handling! 🚀"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "name": "Real CUDA Fluid Simulation - Fixed PTX",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}

with open('cuda_fluid_simulation.ipynb', 'w') as f:
    json.dump(notebook, f, indent=2)

print('✅ Updated CUDA notebook with PTX compatibility fixes!')
print('🔧 Key improvements:')
print('   - GPU compute capability detection')
print('   - Architecture-specific compilation flags') 
print('   - PTX toolchain error handling')
print('   - Simple compatibility test')
print('   - Comprehensive troubleshooting guide') 